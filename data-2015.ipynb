{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36ff152a-6be7-4a14-96ec-7d5b849cbbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /home/pturn22/econ470/a0/pyenv/lib/python3.13/site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in /home/pturn22/econ470/a0/pyenv/lib/python3.13/site-packages (from openpyxl) (2.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from functions import (load_month, load_month_sa, load_month_pen, mapd_clean_merge)\n",
    "!pip install openpyxl\n",
    "\n",
    "# Settings\n",
    "monthlist = [f\"{m:02d}\" for m in range(1, 3)]  # \"01\", \"02\"\n",
    "y = 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e53770ca-be57-41a1-ad61-5892a5e24fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2251623, 19)\n",
      "  contractid  planid                                 org_type  \\\n",
      "0      90091     NaN                         HCPP - 1833 Cost   \n",
      "1      E0654   801.0  Employer/Union Only Direct Contract PDP   \n",
      "2      E0654   801.0  Employer/Union Only Direct Contract PDP   \n",
      "3      E0654   801.0  Employer/Union Only Direct Contract PDP   \n",
      "4      E0654   801.0  Employer/Union Only Direct Contract PDP   \n",
      "\n",
      "                                 plan_type partd snp eghp  \\\n",
      "0                         HCPP - 1833 Cost    No  No   No   \n",
      "1  Employer/Union Only Direct Contract PDP   Yes  No  Yes   \n",
      "2  Employer/Union Only Direct Contract PDP   Yes  No  Yes   \n",
      "3  Employer/Union Only Direct Contract PDP   Yes  No  Yes   \n",
      "4  Employer/Union Only Direct Contract PDP   Yes  No  Yes   \n",
      "\n",
      "                                           org_name  \\\n",
      "0  UNITED MINE WORKERS OF AMERICA HLTH & RETIREMENT   \n",
      "1             IBT VOLUNTARY EMPLOYEE BENEFITS TRUST   \n",
      "2             IBT VOLUNTARY EMPLOYEE BENEFITS TRUST   \n",
      "3             IBT VOLUNTARY EMPLOYEE BENEFITS TRUST   \n",
      "4             IBT VOLUNTARY EMPLOYEE BENEFITS TRUST   \n",
      "\n",
      "                                  org_marketing_name  \\\n",
      "0  United Mine Workers of America Health & Retire...   \n",
      "1  TEAMStar Medicare Part D Prescription Drug Pro...   \n",
      "2  TEAMStar Medicare Part D Prescription Drug Pro...   \n",
      "3  TEAMStar Medicare Part D Prescription Drug Pro...   \n",
      "4  TEAMStar Medicare Part D Prescription Drug Pro...   \n",
      "\n",
      "                                           plan_name  \\\n",
      "0                                                NaN   \n",
      "1  IBT Voluntary Employee Benefits Trust (Employe...   \n",
      "2  IBT Voluntary Employee Benefits Trust (Employe...   \n",
      "3  IBT Voluntary Employee Benefits Trust (Employe...   \n",
      "4  IBT Voluntary Employee Benefits Trust (Employe...   \n",
      "\n",
      "                              parent_org       contract_date      ssa  fips  \\\n",
      "0       UMWA Health and Retirement Funds  02/01/1974 0:00:00      NaN   NaN   \n",
      "1  IBT Voluntary Employee Benefits Trust  01/01/2007 0:00:00  58160.0   NaN   \n",
      "2  IBT Voluntary Employee Benefits Trust  01/01/2007 0:00:00  61000.0   NaN   \n",
      "3  IBT Voluntary Employee Benefits Trust  01/01/2007 0:00:00  96001.0   NaN   \n",
      "4  IBT Voluntary Employee Benefits Trust  01/01/2007 0:00:00   2275.0   NaN   \n",
      "\n",
      "  state county  enrollment  month  year  \n",
      "0   NaN    NaN         NaN      1  2015  \n",
      "1   NaN    NaN         NaN      1  2015  \n",
      "2   NaN    NaN         NaN      1  2015  \n",
      "3   NaN    NaN         NaN      1  2015  \n",
      "4   NaN    NaN         NaN      1  2015  \n"
     ]
    }
   ],
   "source": [
    "test = load_month(\"01\", 2015)\n",
    "print(test.shape)\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61aa95d8-bb05-46af-a244-736438649e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1872428/1774076550.py:17: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  lambda x: x.ffill().bfill()\n",
      "/tmp/ipykernel_1872428/1774076550.py:58: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  plan_data_2015 = plan_data.groupby(['contractid', 'planid', 'fips', 'year']).apply(agg_plan_year).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plan data shape: (2258499, 23)\n"
     ]
    }
   ],
   "source": [
    "# Plan (enrollment & contract) data \n",
    "# Load and combine monthly data\n",
    "plan_data = pd.concat([load_month(m, y) for m in monthlist], ignore_index=True)\n",
    "\n",
    "# Sort data\n",
    "plan_data = plan_data.sort_values(['contractid', 'planid', 'state', 'county', 'month'])\n",
    "\n",
    "# Fill fips by state/county groups\n",
    "plan_data['fips'] = plan_data.groupby(['state', 'county'])['fips'].transform(\n",
    "    lambda x: x.ffill().bfill()\n",
    ")\n",
    "\n",
    "# Fill plan-level attributes\n",
    "plan_cols = ['plan_type', 'partd', 'snp', 'eghp', 'plan_name']\n",
    "for col in plan_cols:\n",
    "    plan_data[col] = plan_data.groupby(['contractid', 'planid'])[col].transform(\n",
    "        lambda x: x.ffill().bfill()\n",
    "    )\n",
    "\n",
    "# Fill contract-level attributes\n",
    "contract_cols = ['org_type', 'org_name', 'org_marketing_name', 'parent_org']\n",
    "for col in contract_cols:\n",
    "    plan_data[col] = plan_data.groupby(['contractid'])[col].transform(\n",
    "        lambda x: x.ffill().bfill()\n",
    "    )\n",
    "\n",
    "# Sort for aggregation\n",
    "plan_data = plan_data.sort_values(['contractid', 'planid', 'fips', 'year', 'month'])\n",
    "\n",
    "# Aggregate to yearly level\n",
    "def agg_plan_year(group):\n",
    "    nonmiss = group['enrollment'].notna()\n",
    "    n = nonmiss.sum()\n",
    "    enroll_vals = group.loc[nonmiss, 'enrollment']\n",
    "    \n",
    "    return pd.Series({\n",
    "        'n_nonmiss': n,\n",
    "        'avg_enrollment': enroll_vals.mean() if n > 0 else np.nan,\n",
    "        'sd_enrollment': enroll_vals.std() if n > 1 else np.nan,\n",
    "        'min_enrollment': enroll_vals.min() if n > 0 else np.nan,\n",
    "        'max_enrollment': enroll_vals.max() if n > 0 else np.nan,\n",
    "        'first_enrollment': enroll_vals.iloc[0] if n > 0 else np.nan,\n",
    "        'last_enrollment': enroll_vals.iloc[-1] if n > 0 else np.nan,\n",
    "        'state': group['state'].iloc[-1],\n",
    "        'county': group['county'].iloc[-1],\n",
    "        'org_type': group['org_type'].iloc[-1],\n",
    "        'plan_type': group['plan_type'].iloc[-1],\n",
    "        'partd': group['partd'].iloc[-1],\n",
    "        'snp': group['snp'].iloc[-1],\n",
    "        'eghp': group['eghp'].iloc[-1],\n",
    "        'org_name': group['org_name'].iloc[-1],\n",
    "        'org_marketing_name': group['org_marketing_name'].iloc[-1],\n",
    "        'plan_name': group['plan_name'].iloc[-1],\n",
    "        'parent_org': group['parent_org'].iloc[-1],\n",
    "        'contract_date': group['contract_date'].iloc[-1]\n",
    "    })\n",
    "\n",
    "plan_data_2015 = plan_data.groupby(['contractid', 'planid', 'fips', 'year']).apply(agg_plan_year).reset_index()\n",
    "print(f\"Plan data shape: {plan_data_2015.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89e54954-c685-48ed-9703-2231ce763935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MA_Cnty_SA_2011_07.csv', 'MA_Cnty_SA_2020_07.csv', 'MA_Cnty_SA_2015_06.csv', 'MA_Cnty_SA_2022_03.csv', 'MA_Cnty_SA_2023_02.csv', 'MA_Cnty_SA_2023_01.csv', 'MA_Cnty_SA_2022_01.csv', 'Read_Me_MA_Cnty_SA_2021.txt', 'MA_Cnty_SA_2015_09.csv', 'MA_Cnty_SA_2024_09.csv', 'MA_Cnty_SA_2023_06.csv', 'MA_Cnty_SA_2015_10.csv', 'MA_Cnty_SA_2009_06.csv', 'MA_Cnty_SA_2010_02.csv', 'MA_Cnty_SA_2018_10.csv', 'MA_Cnty_SA_2021_11.csv', 'MA_Cnty_SA_2020_09.csv', 'Read_Me_MA_Cnty_SA_2018.txt', 'MA_Cnty_SA_2013_02.csv', 'MA_Cnty_SA_200805.csv', 'MA_Cnty_SA_2018_07.csv', 'MA_Cnty_SA_2018_09.csv', 'MA_Cnty_SA_2021_09.csv', 'MA_Cnty_SA_2020_08.csv', 'MA_Cnty_SA_2020_10.csv', 'Read_Me_MA_Cnty_SA_2023.txt', 'Read_Me_MA_Cnty_SA_2024.txt', 'MA_Cnty_SA_2016_01.csv', 'MA_Cnty_SA_2009_12.csv', 'MA_Cnty_SA_2011_10.csv', 'MA_Cnty_SA_2016_07.csv', 'MA_Cnty_SA_2013_07.csv', 'MA_Cnty_SA_2024_08.csv', 'MA_Cnty_SA_2017_02.csv', 'MA_Cnty_SA_2014_02.csv', 'MA_Cnty_SA_2019_03.csv', 'MA_Cnty_SA_2024_07.csv', 'MA_Cnty_SA_2020_06.csv', 'MA_Cnty_SA_200801.csv', 'MA_Cnty_SA_2013_11.csv', 'MA_Cnty_SA_200610.csv', 'MA_Cnty_SA_200704.csv', 'MA_Cnty_SA_200710.csv', 'MA_Cnty_SA_200812.csv', 'Read_Me_MA_Cnty_SA_2017.txt', 'MA_Cnty_SA_2021_04.csv', 'MA_Cnty_SA_2010_10.csv', 'MA_Cnty_SA_2013_06.csv', 'MA_Cnty_SA_2019_12.csv', 'MA_Cnty_SA_2022_10.csv', 'MA_Cnty_SA_200808.csv', 'MA_Cnty_SA_2012_09.csv', 'MA_Cnty_SA_2014_01.csv', 'MA_Cnty_SA_2012_01.csv', 'MA_Cnty_SA_2012_10.csv', 'MA_Cnty_SA_2014_10.csv', 'Read_Me_MA_Cnty_SA_2009.txt', 'MA_Cnty_SA_2021_06.csv', 'MA_Cnty_SA_2009_04.csv', 'MA_Cnty_SA_2017_06.csv', 'MA_Cnty_SA_2024_02.csv', 'MA_Cnty_SA_2016_03.csv', 'MA_Cnty_SA_200702.csv', 'MA_Cnty_SA_2014_07.csv', 'MA_Cnty_SA_2020_03.csv', 'MA_Cnty_SA_200706.csv', 'MA_Cnty_SA_2016_09.csv', 'MA_Cnty_SA_2019_04.csv', 'MA_Cnty_SA_2017_10.csv', 'MA_Cnty_SA_200612.csv', 'MA_Cnty_SA_200807.csv', 'MA_Cnty_SA_2010_03.csv', 'MA_Cnty_SA_2024_12.csv', 'MA_Cnty_SA_2021_05.csv', 'MA_Cnty_SA_2018_01.csv', 'MA_Cnty_SA_200707.csv', 'MA_Cnty_SA_2018_12.csv', 'MA_Cnty_SA_2021_12.csv', 'MA_Cnty_SA_2020_01.csv', 'MA_Cnty_SA_2012_12.csv', 'MA_Cnty_SA_2013_09.csv', 'MA_Cnty_SA_2019_08.csv', 'MA_Cnty_SA_2009_05.csv', 'MA_Cnty_SA_2009_11.csv', 'MA_Cnty_SA_2021_10.csv', 'Read_Me_MA_Cnty_SA_2019.txt', 'MA_Cnty_SA_2009_01.csv', 'MA_Cnty_SA_200705.csv', 'MA_Cnty_SA_2020_04.csv', 'MA_Cnty_SA_2016_05.csv', 'MA_Cnty_SA_200611.csv', 'MA_Cnty_SA_2012_03.csv', 'MA_Cnty_SA_2010_05.csv', 'MA_Cnty_SA_2016_02.csv', 'MA_Cnty_SA_2023_10.csv', 'MA_Cnty_SA_2022_04.csv', 'MA_Cnty_SA_2015_04.csv', 'MA_Cnty_SA_2023_11.csv', 'MA_Cnty_SA_2015_08.csv', 'MA_Cnty_SA_2010_09.csv', 'MA_Cnty_SA_2018_02.csv', 'MA_Cnty_SA_2011_05.csv', 'MA_Cnty_SA_2019_01.csv', 'MA_Cnty_SA_2012_04.csv', 'MA_Cnty_SA_200712.csv', 'MA_Cnty_SA_2009_02.csv', 'MA_Cnty_SA_2014_08.csv', 'MA_Cnty_SA_2016_04.csv', 'MA_Cnty_SA_2018_04.csv', 'MA_Cnty_SA_2011_08.csv', 'MA_Cnty_SA_2021_07.csv', 'MA_Cnty_SA_2024_06.csv', 'MA_Cnty_SA_2019_07.csv', 'MA_Cnty_SA_2024_05.csv', 'MA_Cnty_SA_2020_02.csv', 'MA_Cnty_SA_2015_05.csv', 'MA_Cnty_SA_2024_01.csv', 'MA_Cnty_SA_2012_07.csv', 'MA_Cnty_SA_2016_08.csv', 'MA_Cnty_SA_2018_11.csv', 'MA_Cnty_SA_2022_11.csv', 'MA_Cnty_SA_2014_11.csv', 'readme_ma_cnty_sa_2008.txt', 'MA_Cnty_SA_2010_07.csv', 'Read_Me_MA_Cnty_SA_2012.txt', 'MA_Cnty_SA_2020_05.csv', 'MA_Cnty_SA_2015_02.csv', 'MA_Cnty_SA_200709.csv', 'MA_Cnty_SA_2013_12.csv', 'MA_Cnty_SA_2021_03.csv', 'Read_Me_MA_Cnty_SA_2016.txt', 'MA_Cnty_SA_2014_03.csv', 'MA_Cnty_SA_2010_11.csv', 'MA_Cnty_SA_2010_04.csv', 'MA_Cnty_SA_2024_11.csv', 'MA_Cnty_SA_2015_03.csv', 'MA_Cnty_SA_2023_05.csv', 'MA_Cnty_SA_2022_07.csv', 'Read_Me_MA_Cnty_SA_2011.txt', 'MA_Cnty_SA_2010_01.csv', 'MA_Cnty_SA_2011_06.csv', 'MA_Cnty_SA_2021_01.csv', 'MA_Cnty_SA_2015_11.csv', 'MA_Cnty_SA_2012_02.csv', 'MA_Cnty_SA_2012_08.csv', 'MA_Cnty_SA_2022_08.csv', 'MA_Cnty_SA_2009_09.csv', 'MA_Cnty_SA_200802.csv', 'MA_Cnty_SA_200809.csv', 'MA_Cnty_SA_2014_05.csv', 'MA_Cnty_SA_2016_12.csv', 'MA_Cnty_SA_2013_10.csv', 'readme_ma_cnty_sa.txt', 'MA_Cnty_SA_2019_11.csv', 'MA_Cnty_SA_2024_03.csv', 'MA_Cnty_SA_2017_04.csv', 'MA_Cnty_SA_200811.csv', 'MA_Cnty_SA_200804.csv', 'MA_Cnty_SA_2019_09.csv', 'MA_Cnty_SA_2014_12.csv', 'MA_Cnty_SA_2013_04.csv', 'MA_Cnty_SA_2017_11.csv', 'MA_Cnty_SA_2018_03.csv', 'MA_Cnty_SA_2011_02.csv', 'MA_Cnty_SA_2012_05.csv', 'MA_Cnty_SA_200810.csv', 'MA_Cnty_SA_2013_03.csv', 'MA_Cnty_SA_2023_09.csv', 'MA_Cnty_SA_2011_03.csv', 'MA_Cnty_SA_2017_12.csv', 'MA_Cnty_SA_2013_05.csv', 'MA_Cnty_SA_2020_12.csv', 'MA_Cnty_SA_2014_09.csv', 'MA_Cnty_SA_2013_08.csv', 'MA_Cnty_SA_2015_12.csv', 'Read_Me_MA_Cnty_SA_2015.txt', 'MA_Cnty_SA_2011_04.csv', 'MA_Cnty_SA_2014_04.csv', 'MA_Cnty_SA_200711.csv', 'MA_Cnty_SA_2011_01.csv', 'Read_Me_MA_Cnty_SA_2014.txt', 'MA_Cnty_SA_2024_10.csv', 'MA_Cnty_SA_2017_09.csv', 'MA_Cnty_SA_2009_07.csv', 'MA_Cnty_SA_200701.csv', 'MA_Cnty_SA_2018_08.csv', 'MA_Cnty_SA_2015_01.csv', 'MA_Cnty_SA_2016_11.csv', 'MA_Cnty_SA_2021_02.csv', 'MA_Cnty_SA_2011_11.csv', 'MA_Cnty_SA_2019_10.csv', 'MA_Cnty_SA_2019_02.csv', 'MA_Cnty_SA_2017_08.csv', 'MA_Cnty_SA_2023_08.csv', 'MA_Cnty_SA_2023_07.csv', 'MA_Cnty_SA_2016_10.csv', 'MA_Cnty_SA_2022_02.csv', 'MA_Cnty_SA_2023_12.csv', 'MA_Cnty_SA_200806.csv', 'MA_Cnty_SA_2018_05.csv', 'MA_Cnty_SA_2017_01.csv', 'MA_Cnty_SA_2022_06.csv', 'MA_Cnty_SA_2011_09.csv', 'MA_Cnty_SA_2020_11.csv', 'MA_Cnty_SA_2017_05.csv', 'MA_Cnty_SA_2019_05.csv', 'MA_Cnty_SA_2009_03.csv', 'MA_Cnty_SA_2021_08.csv', 'Read_Me_MA_Cnty_SA_2013.txt', 'MA_Cnty_SA_2023_04.csv', 'MA_Cnty_SA_2010_08.csv', 'MA_Cnty_SA_2022_05.csv', 'MA_Cnty_SA_2009_10.csv', 'MA_Cnty_SA_2012_11.csv', 'MA_Cnty_SA_200803.csv', 'Read_Me_MA_Cnty_SA_2020.txt', 'MA_Cnty_SA_2010_06.csv', 'readme_ma_cnty_sa_2007.txt', 'MA_Cnty_SA_2009_08.csv', 'MA_Cnty_SA_2017_07.csv', 'MA_Cnty_SA_2022_12.csv', 'MA_Cnty_SA_2018_06.csv', 'MA_Cnty_SA_2014_06.csv', 'MA_Cnty_SA_2017_03.csv', 'MA_Cnty_SA_2024_04.csv', 'MA_Cnty_SA_200708.csv', 'MA_Cnty_SA_200703.csv', 'MA_Cnty_SA_2023_03.csv', 'MA_Cnty_SA_2011_12.csv', 'MA_Cnty_SA_2012_06.csv', 'Read_Me_MA_Cnty_SA_2010.txt', 'MA_Cnty_SA_2022_09.csv', 'MA_Cnty_SA_2015_07.csv', 'Read_Me_MA_Cnty_SA_2022.txt', 'MA_Cnty_SA_2016_06.csv', 'MA_Cnty_SA_2019_06.csv', 'MA_Cnty_SA_2013_01.csv']\n"
     ]
    }
   ],
   "source": [
    "folder = \"../ma-data/ma/service-area/Extracted Data/\"\n",
    "import os\n",
    "print(os.listdir(folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62510477-0dba-4035-8486-526d5a9e5c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/pturn22/econ470/a0/work/hwk2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "508879b8-1023-4222-8fd0-00d3b2c6107a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found service area files:\n",
      "['../ma-data/ma/service-area/Extracted Data/MA_Cnty_SA_2015_06.csv', '../ma-data/ma/service-area/Extracted Data/MA_Cnty_SA_2015_09.csv', '../ma-data/ma/service-area/Extracted Data/MA_Cnty_SA_2015_10.csv', '../ma-data/ma/service-area/Extracted Data/MA_Cnty_SA_2015_04.csv', '../ma-data/ma/service-area/Extracted Data/MA_Cnty_SA_2015_08.csv', '../ma-data/ma/service-area/Extracted Data/MA_Cnty_SA_2015_05.csv', '../ma-data/ma/service-area/Extracted Data/MA_Cnty_SA_2015_02.csv', '../ma-data/ma/service-area/Extracted Data/MA_Cnty_SA_2015_03.csv', '../ma-data/ma/service-area/Extracted Data/MA_Cnty_SA_2015_11.csv', '../ma-data/ma/service-area/Extracted Data/MA_Cnty_SA_2015_12.csv', '../ma-data/ma/service-area/Extracted Data/MA_Cnty_SA_2015_01.csv', '../ma-data/ma/service-area/Extracted Data/MA_Cnty_SA_2015_07.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "sa_folder = \"../ma-data/ma/service-area/Extracted Data\"\n",
    "files = [f for f in os.listdir(sa_folder) if f.startswith(f\"MA_Cnty_SA_{y}_\") and f.endswith(\".csv\")]\n",
    "files = [os.path.join(sa_folder, f) for f in files]  # full paths\n",
    "print(\"Found service area files:\")\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c263b2a5-8315-4387-85d2-5baf6543df5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1872428/128791298.py:3: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(f\"../ma-data/ma/service-area/Extracted Data/MA_Cnty_SA_{y}_{m}.csv\")\n",
      "/tmp/ipykernel_1872428/128791298.py:3: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(f\"../ma-data/ma/service-area/Extracted Data/MA_Cnty_SA_{y}_{m}.csv\")\n",
      "/tmp/ipykernel_1872428/128791298.py:3: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(f\"../ma-data/ma/service-area/Extracted Data/MA_Cnty_SA_{y}_{m}.csv\")\n",
      "/tmp/ipykernel_1872428/128791298.py:3: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(f\"../ma-data/ma/service-area/Extracted Data/MA_Cnty_SA_{y}_{m}.csv\")\n",
      "/tmp/ipykernel_1872428/128791298.py:3: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(f\"../ma-data/ma/service-area/Extracted Data/MA_Cnty_SA_{y}_{m}.csv\")\n",
      "/tmp/ipykernel_1872428/128791298.py:3: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(f\"../ma-data/ma/service-area/Extracted Data/MA_Cnty_SA_{y}_{m}.csv\")\n",
      "/tmp/ipykernel_1872428/128791298.py:3: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(f\"../ma-data/ma/service-area/Extracted Data/MA_Cnty_SA_{y}_{m}.csv\")\n",
      "/tmp/ipykernel_1872428/128791298.py:3: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(f\"../ma-data/ma/service-area/Extracted Data/MA_Cnty_SA_{y}_{m}.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['contract id', 'organization name', 'organization type', 'plan type', 'partial', 'eghp', 'ssa', 'fips', 'county', 'state', 'notes']\n"
     ]
    }
   ],
   "source": [
    "service_year = pd.concat(\n",
    "    [\n",
    "        pd.read_csv(f\"../ma-data/ma/service-area/Extracted Data/MA_Cnty_SA_{y}_{m}.csv\")\n",
    "          .rename(columns=lambda x: x.strip().lower())  # lowercase & strip spaces\n",
    "        for m in monthlist\n",
    "    ],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "print(service_year.columns.tolist())  # check if 'contractid' is there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3305a68a-ebf2-4b12-a143-186457fe488d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1872428/1544421988.py:3: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(f\"../ma-data/ma/service-area/Extracted Data/MA_Cnty_SA_{y}_{m}.csv\")\n",
      "/tmp/ipykernel_1872428/1544421988.py:3: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(f\"../ma-data/ma/service-area/Extracted Data/MA_Cnty_SA_{y}_{m}.csv\")\n",
      "/tmp/ipykernel_1872428/1544421988.py:3: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(f\"../ma-data/ma/service-area/Extracted Data/MA_Cnty_SA_{y}_{m}.csv\")\n",
      "/tmp/ipykernel_1872428/1544421988.py:3: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(f\"../ma-data/ma/service-area/Extracted Data/MA_Cnty_SA_{y}_{m}.csv\")\n",
      "/tmp/ipykernel_1872428/1544421988.py:3: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(f\"../ma-data/ma/service-area/Extracted Data/MA_Cnty_SA_{y}_{m}.csv\")\n",
      "/tmp/ipykernel_1872428/1544421988.py:3: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(f\"../ma-data/ma/service-area/Extracted Data/MA_Cnty_SA_{y}_{m}.csv\")\n",
      "/tmp/ipykernel_1872428/1544421988.py:3: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(f\"../ma-data/ma/service-area/Extracted Data/MA_Cnty_SA_{y}_{m}.csv\")\n",
      "/tmp/ipykernel_1872428/1544421988.py:3: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(f\"../ma-data/ma/service-area/Extracted Data/MA_Cnty_SA_{y}_{m}.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['contractid', 'org_name', 'org_type', 'plan type', 'partial', 'eghp', 'ssa', 'fips', 'county', 'state', 'notes']\n"
     ]
    }
   ],
   "source": [
    "service_year = pd.concat(\n",
    "    [\n",
    "        pd.read_csv(f\"../ma-data/ma/service-area/Extracted Data/MA_Cnty_SA_{y}_{m}.csv\")\n",
    "          .rename(columns=lambda x: x.strip().lower())\n",
    "          .rename(columns={\n",
    "              'contract id': 'contractid',\n",
    "              'organization name': 'org_name',\n",
    "              'organization type': 'org_type'\n",
    "          })\n",
    "        for m in monthlist\n",
    "    ],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "print(service_year.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78e7646b-60e9-4d01-8b90-d5eff31cc2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['contract_id', 'organization_name', 'organization_type', 'plan_type', 'partial', 'eghp', 'ssa', 'fips', 'county', 'state', 'notes']\n"
     ]
    }
   ],
   "source": [
    "service_year = service_year.rename(columns={'plan type': 'plan_type'})\n",
    "# Load all monthly service area CSVs\n",
    "service_year = pd.concat([\n",
    "    pd.read_csv(f\"../ma-data/ma/service-area/Extracted Data/MA_Cnty_SA_{y}_{m}.csv\",\n",
    "                dtype=str, low_memory=False)\n",
    "    for m in monthlist\n",
    "], ignore_index=True)\n",
    "\n",
    "# Standardize column names: lowercase + remove spaces\n",
    "service_year.columns = service_year.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "\n",
    "# Now let's check the columns\n",
    "print(service_year.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e555161-17ee-4121-8c53-ec4c405ae999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After reading CSVs into service_year\n",
    "service_year.columns = service_year.columns.str.strip()  # remove leading/trailing spaces\n",
    "service_year = service_year.rename(columns={\n",
    "    'contract id': 'contract_id',\n",
    "    'organization name': 'organization_name',\n",
    "    'organization type': 'organization_type',\n",
    "    'plan type': 'plan_type'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79d6fe1b-caee-4bed-815a-db538b3b2e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after cleaning: ['contract_id', 'org_name', 'org_type', 'plan_type', 'partial', 'eghp', 'ssa', 'fips', 'county', 'state', 'notes', 'month', 'year']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1872428/1787193820.py:56: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  lambda x: x.ffill().bfill()\n",
      "/tmp/ipykernel_1872428/1787193820.py:56: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  lambda x: x.ffill().bfill()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service area data shape: (377723, 12)\n"
     ]
    }
   ],
   "source": [
    "# Service Data\n",
    "# Set working directory (optional, just to be sure)\n",
    "os.getcwd()\n",
    "\n",
    "# Year and months\n",
    "y = 2015\n",
    "monthlist = [f\"{i:02d}\" for i in range(1, 13)]  # '01' to '12'\n",
    "\n",
    "# Function to clean column names for consistency\n",
    "def clean_service_columns(df):\n",
    "    # Strip spaces, lowercase, replace spaces with underscores\n",
    "    df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "    \n",
    "    # Rename known columns to standard names\n",
    "    df = df.rename(columns={\n",
    "        'contractid': 'contract_id',\n",
    "        'contract_id': 'contract_id',\n",
    "        'organization_name': 'org_name',\n",
    "        'organization_type': 'org_type',\n",
    "        'plan_type': 'plan_type'\n",
    "    })\n",
    "    return df\n",
    "\n",
    "# Load all monthly service area CSVs\n",
    "service_dfs = []\n",
    "for m in monthlist:\n",
    "    path = f\"../ma-data/ma/service-area/Extracted Data/MA_Cnty_SA_{y}_{m}.csv\"\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_csv(path, dtype=str, encoding=\"latin-1\")\n",
    "        df = clean_service_columns(df)\n",
    "        df['month'] = int(m)\n",
    "        df['year'] = y\n",
    "        service_dfs.append(df)\n",
    "    else:\n",
    "        print(f\"Warning: file not found: {path}\")\n",
    "\n",
    "# Combine all months\n",
    "service_year = pd.concat(service_dfs, ignore_index=True)\n",
    "\n",
    "# Check columns\n",
    "print(\"Columns after cleaning:\", list(service_year.columns))\n",
    "\n",
    "# Sort for stable fills\n",
    "service_year = service_year.sort_values(['contract_id', 'fips', 'state', 'county', 'month'])\n",
    "\n",
    "# Fill fips by state/county groups\n",
    "service_year['fips'] = service_year.groupby(['state', 'county'])['fips'].transform(\n",
    "    lambda x: x.ffill().bfill()\n",
    ")\n",
    "\n",
    "# Fill contract-level attributes\n",
    "contract_cols_sa = ['plan_type', 'partial', 'eghp', 'org_type', 'org_name']\n",
    "for col in contract_cols_sa:\n",
    "    if col in service_year.columns:\n",
    "        service_year[col] = service_year.groupby(['contract_id'])[col].transform(\n",
    "            lambda x: x.ffill().bfill()\n",
    "        )\n",
    "\n",
    "# Collapse to yearly: one row per contract x county (fips) x year\n",
    "service_year = service_year.sort_values(['contract_id', 'fips', 'year', 'month'])\n",
    "\n",
    "service_data_2015 = service_year.groupby(['contract_id', 'fips', 'year']).agg({\n",
    "    'state': 'last',\n",
    "    'county': 'last',\n",
    "    'org_name': 'last',\n",
    "    'org_type': 'last',\n",
    "    'plan_type': 'last',\n",
    "    'partial': 'last',\n",
    "    'eghp': 'last',\n",
    "    'ssa': 'last',\n",
    "    'notes': 'last'\n",
    "}).reset_index()\n",
    "\n",
    "print(f\"Service area data shape: {service_data_2015.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1aa46235-ba95-437a-8ded-c0bea0c3875a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Landscape data shape: (45059, 11)\n"
     ]
    }
   ],
   "source": [
    "# Plan Characteristics (premium) Data\n",
    "\n",
    "y = 2015\n",
    "\n",
    "# --- MA landscape data (A to M) ---\n",
    "ma_path_a = \"../ma-data/ma/landscape/Extracted Data/2015LandscapeSource file MA_AtoM 11042014.csv\"\n",
    "ma_col_names = [\"state\", \"county\", \"org_name\", \"plan_name\", \"plan_type\", \"premium\", \"partd_deductible\",\n",
    "                \"drug_type\", \"gap_coverage\", \"drug_type_detail\", \"contractid\",\n",
    "                \"planid\", \"segmentid\", \"moop\", \"star_rating\"]\n",
    "\n",
    "ma_data_a = pd.read_csv(ma_path_a, skiprows=6, dtype=str, encoding=\"latin-1\")\n",
    "ma_data_a.columns = ma_col_names[:len(ma_data_a.columns)]\n",
    "\n",
    "# Clean numeric columns\n",
    "for col in ['premium', 'partd_deductible']:\n",
    "    ma_data_a[col] = ma_data_a[col].str.replace('-', '0')\n",
    "    ma_data_a[col] = pd.to_numeric(ma_data_a[col].str.replace(r'[^\\d.]', '', regex=True), errors='coerce')\n",
    "\n",
    "ma_data_a['planid'] = pd.to_numeric(ma_data_a['planid'], errors='coerce')\n",
    "ma_data_a['segmentid'] = pd.to_numeric(ma_data_a['segmentid'], errors='coerce')\n",
    "\n",
    "\n",
    "# --- MA landscape data (N to W) ---\n",
    "ma_path_b = \"../ma-data/ma/landscape/Extracted Data/2015LandscapeSource file MA_NtoW 11042014.csv\"\n",
    "ma_data_b = pd.read_csv(ma_path_b, skiprows=6, dtype=str, encoding=\"latin-1\")\n",
    "ma_data_b.columns = ma_col_names[:len(ma_data_b.columns)]\n",
    "\n",
    "# Clean numeric columns\n",
    "for col in ['premium', 'partd_deductible']:\n",
    "    ma_data_b[col] = ma_data_b[col].str.replace('-', '0')\n",
    "    ma_data_b[col] = pd.to_numeric(ma_data_b[col].str.replace(r'[^\\d.]', '', regex=True), errors='coerce')\n",
    "\n",
    "ma_data_b['planid'] = pd.to_numeric(ma_data_b['planid'], errors='coerce')\n",
    "ma_data_b['segmentid'] = pd.to_numeric(ma_data_b['segmentid'], errors='coerce')\n",
    "\n",
    "# Combine A-M and N-W\n",
    "ma_data = pd.concat([ma_data_a, ma_data_b], ignore_index=True)\n",
    "\n",
    "\n",
    "# ================================\n",
    "# MA-PD landscape data (Part D)\n",
    "# ================================\n",
    "\n",
    "mapd_path = \"../ma-data/ma/landscape/Extracted Data/PartCD/2015/Medicare Part D 2015 Plan Report 03182015.xls\"\n",
    "mapd_col_names = [\"state\", \"county\", \"org_name\", \"plan_name\", \"contractid\", \"planid\", \"segmentid\",\n",
    "                  \"org_type\", \"plan_type\", \"snp\", \"snp_type\", \"benefit_type\", \"below_benchmark\",\n",
    "                  \"national_pdp\", \"premium_partc\",\n",
    "                  \"premium_partd_basic\", \"premium_partd_supp\", \"premium_partd_total\",\n",
    "                  \"partd_assist_full\", \"partd_assist_75\", \"partd_assist_50\", \"partd_assist_25\",\n",
    "                  \"partd_deductible\", \"deductible_exclusions\", \"increase_coverage_limit\",\n",
    "                  \"gap_coverage\", \"gap_coverage_type\"]\n",
    "\n",
    "# Read Excel sheets without forcing column names\n",
    "mapd_data_a = pd.read_excel(mapd_path, sheet_name=\"Alabama to Montana\", skiprows=4, nrows=15854)\n",
    "mapd_data_b = pd.read_excel(mapd_path, sheet_name=\"Nebraska to Wyoming\", skiprows=4, nrows=20300)\n",
    "\n",
    "# Rename columns to match your expected list (truncate if needed)\n",
    "mapd_data_a.columns = mapd_col_names[:len(mapd_data_a.columns)]\n",
    "mapd_data_b.columns = mapd_col_names[:len(mapd_data_b.columns)]\n",
    "\n",
    "# Combine sheets\n",
    "mapd_data = pd.concat([mapd_data_a, mapd_data_b], ignore_index=True)\n",
    "\n",
    "\n",
    "# ================================\n",
    "# Clean and merge landscape + Part D\n",
    "# ================================\n",
    "\n",
    "landscape_2015 = mapd_clean_merge(ma_data, mapd_data, y)\n",
    "print(f\"Landscape data shape: {landscape_2015.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "681aacdb-908e-44da-be26-612dc6af1e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['State Name', 'County Name', 'FIPSST', 'FIPSCNTY', 'FIPS', 'SSAST', 'SSACNTY', 'SSA', 'Eligibles', 'Enrolled', 'Penetration']\n"
     ]
    }
   ],
   "source": [
    "sample_file = f\"{pen_base_path}/State_County_Penetration_MA_{y}_{monthlist[0]}.csv\"\n",
    "df_sample = pd.read_csv(sample_file, encoding=\"latin-1\")\n",
    "print(df_sample.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa8e324c-0fc7-469a-8b0e-58d57f6e45c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penetration data shape: (3224, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1872428/1176406888.py:63: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  pen_2015 = ma_penetration.groupby(['fips', 'state', 'county', 'year']).apply(agg_penetration).reset_index()\n"
     ]
    }
   ],
   "source": [
    "# Penetration Data\n",
    "# Load and combine monthly penetration data\n",
    "pen_base_path = \"../ma-data/ma/penetration/Extracted Data\"\n",
    "\n",
    "def load_month_pen(m, y, base_path):\n",
    "    path = f\"{base_path}/State_County_Penetration_MA_{y}_{m}.csv\"\n",
    "    df = pd.read_csv(path, encoding=\"latin-1\")\n",
    "    \n",
    "    # Rename columns\n",
    "    df = df.rename(columns={\n",
    "        'State Name': 'state',\n",
    "        'County Name': 'county',\n",
    "        'FIPS': 'fips',\n",
    "        'SSA': 'ssa',\n",
    "        'Eligibles': 'eligibles',\n",
    "        'Enrolled': 'enrolled'\n",
    "    })\n",
    "    \n",
    "    # Remove commas and convert to numeric\n",
    "    df['eligibles'] = pd.to_numeric(df['eligibles'].astype(str).str.replace(',', ''), errors='coerce')\n",
    "    df['enrolled'] = pd.to_numeric(df['enrolled'].astype(str).str.replace(',', ''), errors='coerce')\n",
    "    \n",
    "    df[\"month\"] = int(m)\n",
    "    df[\"year\"] = y\n",
    "    return df\n",
    "\n",
    "# Load all months\n",
    "ma_penetration = pd.concat(\n",
    "    [load_month_pen(m, y, pen_base_path) for m in monthlist],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# Fill missing FIPS\n",
    "ma_penetration['fips'] = ma_penetration.groupby(['state', 'county'])['fips'].transform(\n",
    "    lambda x: x.ffill().bfill()\n",
    ")\n",
    "\n",
    "# Collapse to yearly\n",
    "def agg_penetration(group):\n",
    "    n_elig = group['eligibles'].notna().sum()\n",
    "    n_enrol = group['enrolled'].notna().sum()\n",
    "    elig_vals = group['eligibles'].dropna()\n",
    "    enrol_vals = group['enrolled'].dropna()\n",
    "    \n",
    "    return pd.Series({\n",
    "        'n_elig': n_elig,\n",
    "        'n_enrol': n_enrol,\n",
    "        'avg_eligibles': elig_vals.mean() if n_elig > 0 else np.nan,\n",
    "        'sd_eligibles': elig_vals.std() if n_elig > 1 else np.nan,\n",
    "        'min_eligibles': elig_vals.min() if n_elig > 0 else np.nan,\n",
    "        'max_eligibles': elig_vals.max() if n_elig > 0 else np.nan,\n",
    "        'first_eligibles': elig_vals.iloc[0] if n_elig > 0 else np.nan,\n",
    "        'last_eligibles': elig_vals.iloc[-1] if n_elig > 0 else np.nan,\n",
    "        'avg_enrolled': enrol_vals.mean() if n_enrol > 0 else np.nan,\n",
    "        'sd_enrolled': enrol_vals.std() if n_enrol > 1 else np.nan,\n",
    "        'min_enrolled': enrol_vals.min() if n_enrol > 0 else np.nan,\n",
    "        'max_enrolled': enrol_vals.max() if n_enrol > 0 else np.nan,\n",
    "        'first_enrolled': enrol_vals.iloc[0] if n_enrol > 0 else np.nan,\n",
    "        'last_enrolled': enrol_vals.iloc[-1] if n_enrol > 0 else np.nan,\n",
    "        'ssa': group['ssa'].iloc[-1] if 'ssa' in group.columns else np.nan\n",
    "    })\n",
    "\n",
    "pen_2015 = ma_penetration.groupby(['fips', 'state', 'county', 'year']).apply(agg_penetration).reset_index()\n",
    "print(f\"Penetration data shape: {pen_2015.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "12e38f58-4935-4439-a67b-912465ee9bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2015PartDPlans.xlsx',\n",
       " 'Plan Payment Data Elements.pdf',\n",
       " '2015PartDReconciliation.xlsx',\n",
       " '2015PartCPlanLevel.xlsx',\n",
       " '2015PartCCountyLevel.xlsx']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\"../ma-data/ma/cms-payment/2015\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1bea467c-78c4-4d11-8de0-780eda4489e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/pturn22/econ470/a0/work/hwk2'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9de2cac-4405-4cc8-aea9-08543fefcd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rebate data shape: (2741, 13)\n"
     ]
    }
   ],
   "source": [
    "# Rebate Data\n",
    "# Part C rebate data\n",
    "ma_path_a = \"../ma-data/ma/cms-payment/2015/2015PartCPlanLevel.xlsx\"\n",
    "risk_rebate_a = pd.read_excel(ma_path_a, skiprows=3, nrows=2824,\n",
    "                               names=[\"contractid\", \"planid\", \"contract_name\", \"plan_type\",\n",
    "                                      \"riskscore_partc\", \"payment_partc\", \"rebate_partc\"])\n",
    "\n",
    "# Clean Part C numeric columns\n",
    "for col in ['riskscore_partc', 'payment_partc', 'rebate_partc']:\n",
    "    risk_rebate_a[col] = pd.to_numeric(\n",
    "        risk_rebate_a[col].astype(str).str.replace(r'[^\\d.-]', '', regex=True),\n",
    "        errors='coerce'\n",
    "    )\n",
    "\n",
    "risk_rebate_a['planid'] = pd.to_numeric(risk_rebate_a['planid'], errors='coerce')\n",
    "risk_rebate_a['year'] = 2015\n",
    "\n",
    "# Part D rebate data\n",
    "ma_path_b = \"../ma-data/ma/cms-payment/2015/2015PartDPlans.xlsx\"\n",
    "risk_rebate_b = pd.read_excel(ma_path_b, skiprows=3, nrows=3898,\n",
    "                               names=[\"contractid\", \"planid\", \"contract_name\", \"plan_type\",\n",
    "                                      \"directsubsidy_partd\", \"riskscore_partd\", \"reinsurance_partd\",\n",
    "                                      \"costsharing_partd\"])\n",
    "\n",
    "# Clean Part D numeric columns\n",
    "for col in ['directsubsidy_partd', 'reinsurance_partd', 'costsharing_partd']:\n",
    "    risk_rebate_b[col] = pd.to_numeric(\n",
    "        risk_rebate_b[col].astype(str).str.replace(r'[^\\d.-]', '', regex=True),\n",
    "        errors='coerce'\n",
    "    )\n",
    "\n",
    "# Total Part D payment\n",
    "risk_rebate_b['payment_partd'] = (risk_rebate_b['directsubsidy_partd'] + \n",
    "                                   risk_rebate_b['reinsurance_partd'] + \n",
    "                                   risk_rebate_b['costsharing_partd'])\n",
    "\n",
    "risk_rebate_b['planid'] = pd.to_numeric(risk_rebate_b['planid'], errors='coerce')\n",
    "\n",
    "# Select relevant columns for Part D\n",
    "risk_rebate_b = risk_rebate_b[['contractid', 'planid', 'payment_partd',\n",
    "                               'directsubsidy_partd', 'reinsurance_partd', 'costsharing_partd',\n",
    "                               'riskscore_partd']]\n",
    "\n",
    "# Merge Part C and Part D data\n",
    "rebate_2015 = risk_rebate_a.merge(risk_rebate_b, on=['contractid', 'planid'], how='left')\n",
    "\n",
    "print(f\"Rebate data shape: {rebate_2015.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9da3cc4c-5a14-4b1e-b060-46040dad39fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aged07.csv', 'FFS18.xlsx', 'AGED08.csv', 'FFS16.xlsx', 'aged13.csv', 'aged10.csv', 'aged09.csv', 'aged11.csv', 'aged14.csv', 'aged12.csv', 'FFS15.xlsx', 'AGED06.csv', 'FFS17_AdvancedNotice.xlsx']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# List files in the directory where the CSV should be\n",
    "ffs_dir = \"../ma-data/ffs-costs/Extracted Data/Aged Only\"\n",
    "print(os.listdir(ffs_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fba5a5bf-7e04-4b56-bb09-377af6617b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFS costs data shape: (3224, 9)\n"
     ]
    }
   ],
   "source": [
    "# FFS costs data\n",
    "ffs_path = \"../ma-data/ffs-costs/Extracted Data/Aged Only/FFS15.xlsx\"\n",
    "ffs_col_names = [\"ssa\", \"state\", \"county_name\", \"parta_enroll\",\n",
    "                 \"parta_reimb\", \"parta_percap\", \"parta_reimb_unadj\",\n",
    "                 \"parta_percap_unadj\", \"parta_ime\", \"parta_dsh\",\n",
    "                 \"parta_gme\", \"partb_enroll\",\n",
    "                 \"partb_reimb\", \"partb_percap\",\n",
    "                 \"mean_risk\"]\n",
    "\n",
    "ffs_data = pd.read_excel(ffs_path, skiprows=2, names=ffs_col_names, na_values=['*', '.'],\n",
    "                       usecols=range(15))\n",
    "\n",
    "# Select and clean\n",
    "ffscosts_2015 = ffs_data[['ssa', 'state', 'county_name', 'parta_enroll', 'parta_reimb',\n",
    "                          'partb_enroll', 'partb_reimb', 'mean_risk']].copy()\n",
    "ffscosts_2015['year'] = 2015\n",
    "ffscosts_2015['ssa'] = pd.to_numeric(ffscosts_2015['ssa'], errors='coerce')\n",
    "\n",
    "for col in ['parta_enroll', 'parta_reimb', 'partb_enroll', 'partb_reimb', 'mean_risk']:\n",
    "    ffscosts_2015[col] = pd.to_numeric(ffscosts_2015[col].astype(str).str.replace(r'[^\\d.-]', '', regex=True), errors='coerce')\n",
    "\n",
    "print(f\"FFS costs data shape: {ffscosts_2015.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a054fd86-7da5-4474-90ac-3a3e1f43139d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['contract_id',\n",
       " 'fips',\n",
       " 'year',\n",
       " 'state',\n",
       " 'county',\n",
       " 'org_name',\n",
       " 'org_type',\n",
       " 'plan_type',\n",
       " 'partial',\n",
       " 'eghp',\n",
       " 'ssa',\n",
       " 'notes']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service_data_2015.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "47001918-8526-477f-ad55-272bca524a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final merged data shape: (51154, 62)\n"
     ]
    }
   ],
   "source": [
    "# Merge Data\n",
    "\n",
    "# Ensure fips is string for merging\n",
    "plan_data_2015['fips'] = plan_data_2015['fips'].astype(str)\n",
    "service_data_2015['fips'] = service_data_2015['fips'].fillna(0).astype(int).astype(str)\n",
    "\n",
    "# Merge plan data with service area\n",
    "ma_2015 = plan_data_2015.merge(\n",
    "    service_data_2015[['contract_id', 'fips']],\n",
    "    left_on=['contractid', 'fips'],\n",
    "    right_on=['contract_id', 'fips'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Filter out territories and certain plan types\n",
    "excluded_states = ['VI', 'PR', 'MP', 'GU', 'AS', '']\n",
    "ma_2015 = ma_2015[\n",
    "    (~ma_2015['state'].isin(excluded_states)) &\n",
    "    (ma_2015['snp'] == 'No') &\n",
    "    ((ma_2015['planid'] < 800) | (ma_2015['planid'] >= 900)) &\n",
    "    (ma_2015['planid'].notna()) &\n",
    "    (ma_2015['fips'].notna())\n",
    "]\n",
    "\n",
    "# Ensure fips is string for penetration merge\n",
    "pen_2015['fips'] = pen_2015['fips'].astype(str)\n",
    "\n",
    "# Prepare penetration data for join\n",
    "pen_2015_join = pen_2015.copy()\n",
    "pen_2015_join = pen_2015_join.rename(columns={'state': 'state_long', 'county': 'county_long'})\n",
    "pen_2015_join['state_long'] = pen_2015_join['state_long'].str.lower()\n",
    "\n",
    "# Keep only unique fips entries\n",
    "pen_2015_join['ncount'] = pen_2015_join.groupby('fips')['fips'].transform('count')\n",
    "pen_2015_join = pen_2015_join[pen_2015_join['ncount'] == 1].drop(columns=['ncount'])\n",
    "\n",
    "# Join penetration data\n",
    "ma_2015 = ma_2015.merge(pen_2015_join, on='fips', how='left', suffixes=('', '_pen'))\n",
    "\n",
    "# Create state name lookup safely\n",
    "state_2015 = ma_2015.groupby('state').agg(\n",
    "    state_name=('state_long', lambda x: x.dropna().iloc[-1] if len(x.dropna()) > 0 else None)\n",
    ").reset_index()\n",
    "\n",
    "# Join state names\n",
    "full_2015 = ma_2015.merge(state_2015, on='state', how='left')\n",
    "\n",
    "# Prepare landscape data for join\n",
    "landscape_2015_join = landscape_2015.copy()\n",
    "landscape_2015_join['state'] = landscape_2015_join['state'].str.lower()\n",
    "\n",
    "# Join landscape data\n",
    "full_2015 = full_2015.merge(\n",
    "    landscape_2015_join,\n",
    "    left_on=['contractid', 'planid', 'state_name', 'county'],\n",
    "    right_on=['contractid', 'planid', 'state', 'county'],\n",
    "    how='left',\n",
    "    suffixes=('', '_land')\n",
    ")\n",
    "\n",
    "# Join rebate data (exclude contract_name and plan_type from rebate)\n",
    "rebate_2015_join = rebate_2015.drop(columns=['contract_name', 'plan_type'], errors='ignore')\n",
    "full_2015 = full_2015.merge(rebate_2015_join, on=['contractid', 'planid'], how='left', suffixes=('', '_reb'))\n",
    "\n",
    "# Calculate basic_premium\n",
    "def calc_basic_premium(row):\n",
    "    if row.get('rebate_partc', 0) > 0:\n",
    "        return 0\n",
    "    elif row.get('partd') == 'No' and pd.notna(row.get('premium')) and pd.isna(row.get('premium_partc')):\n",
    "        return row.get('premium')\n",
    "    else:\n",
    "        return row.get('premium_partc')\n",
    "\n",
    "# Calculate bid\n",
    "def calc_bid(row):\n",
    "    rebate = row.get('rebate_partc', 0) or 0\n",
    "    basic_premium = row.get('basic_premium', 0) or 0\n",
    "    payment_partc = row.get('payment_partc')\n",
    "    riskscore_partc = row.get('riskscore_partc')\n",
    "    \n",
    "    if pd.isna(payment_partc) or pd.isna(riskscore_partc) or riskscore_partc == 0:\n",
    "        return np.nan\n",
    "    elif rebate == 0 and basic_premium > 0:\n",
    "        return (payment_partc + basic_premium) / riskscore_partc\n",
    "    elif rebate > 0 or basic_premium == 0:\n",
    "        return payment_partc / riskscore_partc\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "full_2015['basic_premium'] = full_2015.apply(calc_basic_premium, axis=1)\n",
    "full_2015['bid'] = full_2015.apply(calc_bid, axis=1)\n",
    "\n",
    "print(f\"Final merged data shape: {full_2015.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c088c7c3-a5cf-498f-8f80-d6563e50b6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ../data/output/data-2015.csv\n"
     ]
    }
   ],
   "source": [
    "# Save to CSV\n",
    "output_path = \"../data/output/data-2015.csv\"\n",
    "Path(output_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "full_2015.to_csv(output_path, index=False)\n",
    "print(f\"Data saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73341db-3a1b-4bd7-a8d6-611b5fd92638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (econ470)",
   "language": "python",
   "name": "econ470-a0kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
